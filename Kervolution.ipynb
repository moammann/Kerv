{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kervolution.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RcVEfVTeAueE",
        "djlHOzVvv7Uu",
        "rAn6EJ2HwA9e",
        "oaYwcSH1wI5n",
        "SLtgPoy54ZNh",
        "datF7WqsEcM1"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moammann/Kerv/blob/master/Kervolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djlHOzVvv7Uu",
        "colab_type": "text"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaYwcSH1wI5n",
        "colab_type": "text"
      },
      "source": [
        "## From Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dfKYRR-vgnp",
        "colab_type": "code",
        "outputId": "2c5f7f77-dd24-4746-dd5d-ac3a21175ab6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmZXDXgNwMrT",
        "colab_type": "text"
      },
      "source": [
        "# Kervolution\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyBfvzcdFhj5",
        "colab_type": "text"
      },
      "source": [
        "## Import needed packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wODaFamFwR9B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python '/content/drive/My Drive/Kerv/setup.py' install\n",
        "!pip install gast==0.2.2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdUUNVoaZyNs",
        "colab_type": "text"
      },
      "source": [
        "Restart Runtime and load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-WTYi7FaD4Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtA-wQjQZe5E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sys.path.insert(1, \"/content/drive/My Drive/Kerv\")\n",
        "from tf_keras_kervolution_2d import KernelConv1D, KernelConv2D, PolynomialKernel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLtgPoy54ZNh",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_V4kz224CWS",
        "colab_type": "code",
        "outputId": "a9fb2d57-6ccb-406f-b468-40c47828fb30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from tensorboardcolab import TensorBoardColab, TensorBoardColabCallback\n",
        "tbc=TensorBoardColab()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "https://873e73ec.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuSkIhKC6rfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tensboar = TensorBoardColabCallback(tbc,write_graph=True,write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PovvD-mqbQ-6",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htzdh3QqbTgy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "61d1f3b0-4832-4bb2-ea4d-70e9d00e714d"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, AveragePooling2D\n",
        "from keras import backend as K\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "batch_size = 50\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "datF7WqsEcM1",
        "colab_type": "text"
      },
      "source": [
        "## Mnist, CNN, LeNet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3Z6y5aKRAEt",
        "colab_type": "code",
        "outputId": "85428fb0-b929-4eef-a899-87ed40513837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1),name='Conv1'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu',name='Conv2'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.003, momentum=0.9, nesterov=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv2D)               (None, 26, 26, 6)         60        \n",
            "_________________________________________________________________\n",
            "average_pooling2d_5 (Average (None, 13, 13, 6)         0         \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 11, 11, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_6 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 124us/step - loss: 0.5412 - acc: 0.8367 - val_loss: 0.2135 - val_acc: 0.9347\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.1818 - acc: 0.9437 - val_loss: 0.1508 - val_acc: 0.9547\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.1326 - acc: 0.9588 - val_loss: 0.1120 - val_acc: 0.9645\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.1037 - acc: 0.9684 - val_loss: 0.0963 - val_acc: 0.9704\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0875 - acc: 0.9732 - val_loss: 0.0883 - val_acc: 0.9728\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0750 - acc: 0.9769 - val_loss: 0.0755 - val_acc: 0.9765\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0663 - acc: 0.9794 - val_loss: 0.0704 - val_acc: 0.9779\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0577 - acc: 0.9821 - val_loss: 0.0683 - val_acc: 0.9772\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0536 - acc: 0.9829 - val_loss: 0.0616 - val_acc: 0.9796\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0484 - acc: 0.9849 - val_loss: 0.0623 - val_acc: 0.9804\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0435 - acc: 0.9861 - val_loss: 0.0597 - val_acc: 0.9814\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 7s 121us/step - loss: 0.0405 - acc: 0.9872 - val_loss: 0.0566 - val_acc: 0.9832\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0364 - acc: 0.9883 - val_loss: 0.0575 - val_acc: 0.9827\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0343 - acc: 0.9889 - val_loss: 0.0536 - val_acc: 0.9841\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 0.0318 - acc: 0.9895 - val_loss: 0.0527 - val_acc: 0.9831\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0296 - acc: 0.9906 - val_loss: 0.0595 - val_acc: 0.9826\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 7s 125us/step - loss: 0.0272 - acc: 0.9910 - val_loss: 0.0484 - val_acc: 0.9853\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 7s 123us/step - loss: 0.0247 - acc: 0.9923 - val_loss: 0.0522 - val_acc: 0.9843\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0240 - acc: 0.9921 - val_loss: 0.0601 - val_acc: 0.9817\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 7s 119us/step - loss: 0.0225 - acc: 0.9928 - val_loss: 0.0474 - val_acc: 0.9852\n",
            "Test loss: 0.04736364564303949\n",
            "Test accuracy: 0.9852\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Kiclk_hlBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "  if 'Conv1' in layer.name:\n",
        "    filters1, biases1 = layer.get_weights()\n",
        "  if 'Conv2' in layer.name:\n",
        "    filters2, biases2 = layer.get_weights()\n",
        "filters1 = np.squeeze(filters1)\n",
        "filters2 = np.squeeze(filters2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrL5yXDc7mw8",
        "colab_type": "code",
        "outputId": "6c6e18b6-949d-43b6-dbfd-3192ca25d5d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "i=0\n",
        "\n",
        "for ax in axes.flat:\n",
        "    im = ax.imshow(filters1[:,:,i], cmap='gray')\n",
        "    i+=1\n",
        "\n",
        "fig.colorbar(im, ax=axes.ravel().tolist())\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
        "\n",
        "fig.suptitle('Weights of first CNN layer')\n",
        "plt.savefig('mnist_comp_CNN_standard.pdf')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colorbar.py:214: UserWarning: Use the colorbar set_ticks() method instead.\n",
            "  warnings.warn(\"Use the colorbar set_ticks() method instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASUAAAEICAYAAAAZVeKfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFcVJREFUeJzt3XuwXWV9xvHvEyCHxFwg4SISSAOB\nqVBtHChQK5YCkjhi0Q4mCEWuGsAKU7wA41QswmhkKA3ipSAQrpHbiIAoIoaLFhBSGQgKJoEQ7uEk\nJKRQAoFf/1jvhu1xn5y1s9c5510nz2dmT85el3e9O2flybvevff6KSIwM8vFsMHugJlZM4eSmWXF\noWRmWXEomVlWHEpmlhWHkpllZYMIJUk/kPRvJbedI+nM/u5Ti+NuLekuSaslndNi/QhJN0laJela\nSYdJ+sVA97O/SQpJkwe7HzZ4sgwlSadJ+lmPZQt7WXZIX+1FxHER8Y2K+tZf/2g+B3QDYyLiiy3W\nHwxsDYyPiE9FxJURccD6HKhM8KpwoqQFkl6R9HQKw/c1tRGS9mjaZ7KkaHp+h6TXJG3XtGx/SUvW\np9+2YcgylIC7gA9K2ghA0jbAJsAHeiybnLYdCiYCv4/eP806EfhjRKztqyFJG1fQn9nAScCJwDhg\nZ+AG4GNN26wA+hpVvgKUGqUOlsY5ZZmIiOwewHDgVWC39Hw6cAlwZ49li5r2+UvgNop/KI8B05vW\nzQHObHr+FeA54FngWCCAyU3bfhf4KbAauA/YMa27K237CvC/wAxgC+BmYGU69t3AsF5e1weB+4FV\n6c8PNh3zDeD11O7+Pfb797TujbT+GOBI4NdN2wTweWAh8AQg4FxgGfAy8DDwVxQjsuZj3dSinzsB\nbwJ7rON3NAf4D+B54O/TssnFKfX2NncAp6e/x8bf4f7AknW02/y7+Bjwu9T/p4CvN233U+ALPfZ9\nCPhkyfPh+8At6Xe5f2/98WMQ/v0Pdgd67RjMA/41/Xw+cDRwVo9lF6ef35VO2qOAjYEPUFwK7ZLW\nzyGFEjAt/UPaFRgJXMGfh9JyYI/U1pXAj5r69fa26fk3gR9QjOQ2AfYG1OL1jANeAg5P7X46PR/f\ns4+9/H18Hbii6fmR/Hko3ZaOMwKYCswHNqMIqPcC25Q81nHAk338fuZQjJJObPSD1qF0LEV4XZGW\ntRNK+wDvoxjRvx94AfhEWjcduK9pv79Ov7fhJc+HVcDfpbY3Hezz3Y93HrlevkExKvpw+nlvihHI\n3T2W3Zl+PpDiRL8kItZGxO+A64FPtWh3OnBJRDwSEa9S/GPv6ccR8dsoLpWuBKaso59vANsAEyPi\njYi4O9KZ38PHgIURcXnq41zgUeDj62i7Xd+MiBUR8X+pX6MpRgyKiD9ExHMl2xlPMZIs47+A7SV9\ndF39Aj4uadeSbQIQEXdExMMR8VZEPATMBf4+rb4R2FnSTun54cDVEfE65c6Hn0TEb1Lbr7XTL+tf\nOYfSXcCHJI0DtoyIhcB/U8w1jaO4FGnMJ00E9pS0svEADgPe3aLd91D8L9rwVIttnm/6+VVg1Dr6\neTawCPiFpMclndrLdu8Bnuyx7Elg23W03a63X0tE/IpiNPldYJmkCySNKdnOcoqg7VNErAG+kR69\nbfNi6ssZJY8PgKQ9Jc2T9KKkVRQjuC1Sm68BVwP/LGkYxcjz8rRrmfOh1e/dMpBzKN0DjAU+C/wG\nICJeppgH+izwbEQ8kbZ9CrgzIjZreoyKiONbtPscMKHp+XYttiktIlZHxBcjYgfgH4GTJe3XYtNn\nKf6xNNseeKaT4/fsTo++nRcRuwG7UExUf7nVdi3cDkyQtHvJ415CcZn4T+vY5mzgH4DdSrYJcBXF\niGi7iBhLcZmspvWXUoTNfsCrEXFPWl7mfPDtMTKVbSilS5AHgJMpLtsafp2WNb/rdjPFUP5wSZuk\nx99Iem+Lpq8BjpL0Xkkjaf+doReAHRpPJB2Y3goXxTzFm8BbLfa7JfXxUEkbS5pBERY3t3n8UtLr\n31PSJhSTua819etPXkNPaVT6PWCupH0kDZe0qaRDWo0E02Xu6cAp62hzJXAOxZsMZY0GVkTEa+mj\nB4f2aPOe9JrO4Z1RErR3Plhmsg2l5E5gK4ogarg7LXs7lCJiNXAAcAjFiOR5YBbQ1bPBiPgZcB7F\nRPoi4N60ak3JPn0duDRdFkyneKfqlxTvZN0DfC8i5rU47nKKuY4vUlwefQU4MCK6Sx63XWOACykm\n059Mxzw7rbsI2CW9hht62f9E3rn8WwksBj4J3NTL9nPpex5qNkVol3UCcIak1cDXKP5D6ekyisnw\nKxoL2jkfLD9qPSe74Uj/ey4AuqLEZ4AsL5I+A3wuIj402H2xauQ+UuoXkj4pqUvS5hT/g97kQKqf\ndPl9AnDBYPfFqrNBhhIwk+JDhYspLidaTYhbxiRNBV6kmB+7apC7YxXa4C/fzCwvG+pIycwy5VAy\ns6w4lMwsKw4lM8uKQ8nMsuJQMrOsOJTMLCsOJTPLikPJzLLiUDKzrDiUzCwrDiUzy4pDycyy4lAy\ns6w4lMwsK22Vd0614yvtwKRJkyptr2H48OGVt/noo492R8SWlTe8gRk5cmSMHTu20jb7675gXV3V\n39Z76dKlHZ1H06ZNi+7ucrd2nz9//q0RMW19jzUY2g0lNt1000o7MGvWrErba9huu44qJ7W01157\n9azbZuth7NixHHHEEZW2uXZt/9zNeOedd668zZkzZ3Z0HnV3d3P//feX2nbYsGFbdHKswdBWKJlZ\nHobyHWMdSmY15FAys2xEhEPJzPLy1lutijAPDQ4lsxrySMnMsuJQMrNseE7JzLLjUDKzrDiUzCwr\nfvfNzLLhOSUzy45Dycyy4lAys6w4lMwsGxHhiW4zy4tHSmaWFYeSmWXFoWRm2fDnlJrssMMOfPvb\n3660A7Nnz660vYa77rqrX9q1zo0ePZp999230jYPOOCASttruPbaa/ul3U5VGUqSpgGzgY2AH0bE\nt3qs7wIuA3YDlgMzImKJpL8A/gA8lja9NyKO67Q/HimZ1VBV775J2gj4LvAR4Gngfkk3RsTvmzY7\nBngpIiZLOgSYBcxI6xZHxJRKOpO47ptZDTUu4fp6lLAHsCgiHo+I14EfAQf12OYg4NL083XAfqq6\n1loTh5JZzZQNpJKhtC3wVNPzp9OylttExFpgFTA+rZsk6XeS7pS0d2evrODLN7MaamNOaQtJDzQ9\nvyAiLqioG88B20fEckm7ATdI2jUiXu6kUYeSWQ21EUrdEbH7OtY/AzRXbp2QlrXa5mlJGwNjgeVR\ndGJN6s98SYuBnYEH6IAv38xqqMLLt/uBnSRNkjQcOAS4scc2NwKNksYHA7+KiJC0ZZooR9IOwE7A\n452+No+UzGqmyu++RcRaSf8C3ErxkYCLI+IRSWcAD0TEjcBFwOWSFgErKIIL4MPAGZLeAN4CjouI\nFZ32yaFkVkNVfk4pIm4Bbumx7GtNP78GfKrFftcD11fWkcShZFZD/kS3mWXFoWRmWXEomVk2fJM3\nM8uOR0pmlhWHkpllxaFkZtnwTd7MLDsOJTPLit99M7OseKRkZtnwnJKZZcehlCxbtozzzz+/0g6M\nGTOm0vYa+uOX1o+3Jd6grFmzhscf7/i2O3/iqKOOqrS9hjlz5vRLu51yKJlZVhxKZpYNf/fNzLLj\nkZKZZWUoh5ILB5jVUIWFA5A0TdJjkhZJOrXF+i5JV6f196Vy3Y11p6Xlj0maWsVrcyiZ1VBVodRU\ntvujwC7ApyXt0mOzt8t2A+dSlO0mbXcIsCswDfheo7pJJxxKZjXTmOgu8yihk7LdBwE/iog1EfEE\nsCi11xGHklkNZVK2u8y+bfNEt1kNZVK2u184lMxqKIey3SX3bZsv38xqpuylW3+X7U7LD0nvzk2i\nKNv9205fn0dKZjVU1eeUOinbnba7Bvg9sBb4fES82WmfHEpmNVTl10zWt2x3WncWcFZlncGhZFZL\nQ/kT3Q4ls5rxTd7MLDsOJTPLikPJzLLiUDKzbPgmb2aWHY+UktWrV3fPmzfvyf7qTJX66Sb/E/uj\n0Q3N0qVLu48//vhanEf9pOPzyKGURMSW/dUR23D4POqcQ8nMsuJQMrNseKLbzLLjkZKZZcWhZGZZ\ncSiZWTb8hVwzy45Dycyy4nffzCwrQ3mk5MIBZjVTceGAXkkaJ+k2SQvTn5v3st0RaZuFko5oWn5H\nKuf9YHpsVea4DiWzGhqIUAJOBW6PiJ2A29PzPyFpHHA6sCdFddzTe4TXYRExJT2WlTloW5dv48aN\niwkTJrSzy6BZtqzU62/LCy+80O3vbXWuq6srRo0aVWmbkyZNqrS9hgULFlTe5po1azo+jwbo8u0g\nYJ/086XAHcApPbaZCtwWESsAJN0GTAPmru9B2wqlCRMmcPPNN6/vsVoaNqx/BmvnnXde5W2effbZ\nG/I32yszatQopk6dWmmbV111VaXtNUyePLnyNhcvXtzxeTRAobR1RDyXfn4e2LrFNn2V7r5E0pvA\n9cCZUaLjnug2q5k2v/u2zrLdkn4JvLvFfl/tccyQ1G4SHhYRz0gaTRFKhwOX9bWTQ8mshqoq2x0R\n+/e2TtILkraJiOckbQO0mhN5hncu8aAo3X1HavuZ9OdqSVdRzDn1GUqe6DaroQGa6G4u130E8JMW\n29wKHCBp8zTBfQBwq6SNJW0BIGkT4ECg1ASdR0pmNTRAc0rfAq6RdAzwJDAdQNLuwHERcWxErJD0\nDeD+tM8Zadm7KMJpE4py4L8ELixzUIeSWc0M1HffImI5sF+L5Q8AxzY9vxi4uMc2rwC7rc9xHUpm\nNeSvmZhZVoby10wcSmY15FAys2z4fkpmlh2HkpllxaFkZlnxu29mlg3PKZlZdhxKZpYVh5KZZcWh\nZGbZaPN+SrXjUDKrIY+UzCwrDqVk+PDhbL/99pV2YM6cOZW21zB69Oh+adc6t2rVKm655ZZK26y6\nEEHDK6+80i/tdsqhZGZZcSiZWTb84Ukzy85QfvfNhQPMaiizst0/l7RS0s09lk+SdJ+kRZKuljS8\nzHEdSmY1lEvZ7uRsippuPc0Czo2IycBLwDFlDupQMquZsoFUQSgdRFGum/TnJ3rpz+3A6uZlkgTs\nC1zX1/49eU7JrIYyKtvdm/HAyohYm573LOfdK4eSWQ21EUqDWbZ7vTiUzGqojXff+rtsd2+WA5tJ\n2jiNliZQlPjuk+eUzGpmAOeUypTt7q2PAcwDDm53f4eSWQ0NUCh9C/iIpIXA/uk5knaX9MPGRpLu\nBq4F9pP0tKSpadUpwMmSFlHMMV1U5qC+fDOroczKdu/dy/6PA3u0e1yHklkN+WsmZpYN3+TNzLLj\nkZKZZcWhZGZZcSiZWVYcSmaWDd/kzcyy43ffzCwrHiklS5Ys4eijj660AzfddFOl7TV0d3f3S7vW\nua233pqZM2dW2uZFF5X6BkPbDj300MrbvPDCCztuw6FkZtnwnJKZZcehZGZZcSiZWVb87puZZcNz\nSmaWHYeSmWXFoWRmWRnKoeR7dJvVTOMmb2UenaigbPccSU9IejA9ppQ5rkPJrIZqUrYb4MsRMSU9\nHixzUIeSWQ3lXra7Ew4lsxoaoFDqpGx3w1mSHpJ0rqSuMjt4otushmpStvs0ijAbDlxAUQfujL52\nciiZ1Uybo6DBKttN0yhrjaRLgC+V2c+Xb2Y1NBDvvtFB2W6AFGRIEsV81IIy+zmUzGqoJmW7r5T0\nMPAwsAVwZpmD+vLNrIZqUrZ73/U5rkPJrGb8hVwzy45DycyyMpRDSe28OEkvAk/2X3eyNzEithzs\nTtSdz6POzqPx48fH1KlT+94QmDt37vx1fSQgR22NlPwP0qrg86gznlMys+w4lMwsKw4lM8uKQ8nM\nstG4ydtQ5VAyqyGPlMwsKw4lM8uKQ8nMsuHPKZlZdhxKZpYVv/uWdHV1xYgRIyrtwEYbbVRpew1j\nxoypvM0lS5Z0+ysSnevq6oqRI0dW2uaOO+5YaXsN8+fP749mOz6PPFJKRowYwT777FNpB6o+ORvK\nfmGxHUceeeSG/CXSyowcOZL99vuze4d15Lrrrqu0vYbiTq6V6+g88pySmWVnKIeS79FtVkMDcY/u\nMmW7JU2RdI+kR1J9txlN6yZJuk/SIklXSxpe5rgOJbMaGqBqJmXKdr8KfCYidgWmAf8pabO0bhZw\nbkRMBl4CjilzUIeSWc2UHSUNRNnuiPhjRCxMPz9LURtuy1RWaV/gunXt34rnlMxqaIDmlNoq2y1p\nD4pquIuB8cDKiFibVj8NbFvmoA4lsxrKrWx3Kjx5OXBERLzVybuWDiWzGsqpbLekMcBPga9GxL1p\n8XJgM0kbp9HSBOCZMh32nJJZDQ3QnFKfZbvTO2o/Bi6LiLc/LBbFwecBB69r/1YcSmY107jJ2wC8\n+1ambPd04MPAkZIeTI8pad0pwMmSFlHMMV1U5qC+fDOroVzKdkfEFcAVvez/OLBHu8d1KJnV0FD+\nRLdDyayGHEpmlg1/IdfMsuNQMrOs+CZvZpYVj5TMLBueUzKz7DiUzCwrDqVk8uTJ3HDDDZV2YOnS\npZW21zBz5sx+adc6t9VWW3HCCSdU2ubo0aMrba/hpJNOqrzN2bNnd9yGJ7rNLBueUzKz7DiUzCwr\nDiUzy4pDycyy4lAys2w0bvI2VDmUzGrIIyUzy8pQDiXfo9ushmpStnuOpCda3Lt7nRxKZjUzgBVy\nOy3bDfDliJiSHg+WOahDyayGci/b3clBHUpmNTRAJZY6KdvdcFa6rDtXUleZg3qi26yGci/bnRaf\nRhFmw4ELKOrAndFXhx1KZjXT5qXZYJXtpmmUtUbSJcCXynTYl29mNZR72e60bpv0pyjmoxaUOahD\nyayGBiiUOi3bfaWkh4GHgS2AM8sc1JdvZjU0EF8zqaBs977rc1yHklnN+CZvZpYdh5KZZcWhZGZZ\ncSglL730Etdcc02lHai6qkXD8uXL+6Vd69yyZcv4zne+U2mbM2bM6Huj9bBy5cp+abdTDiUzy4Zv\n8mZm2fFIycyy4lAys6w4lMwsG/7wpJllx6FkZlnxu29mlhWPlMwsG55TMrPsOJTMLCsOJTPLiie6\nzSwbQ31OyffoNquhjMp2T5T0P+ne3I9IOq5p3W6SHpa0SNJ5qYBAnxxKZjWUUdnu54C/jYgpwJ7A\nqZLek9Z9H/gssFN6TCtzUIeSWQ1lVLb79YhYk552kTIllVcaExH3RtGRy1rt34pDyayGBiiUSpXt\nlrSdpIeAp4BZEfEssC3wdNNmT6dlffJEt1nNtHmTt34v2x0RTwHvT5dtN0i6rtV2ZTmUzGoop7Ld\nTW09K2kBsDfwG2BC0+oJwDNlOuzLN7Mayqhs9wRJI9LPmwMfAh5Ll30vS9orvev2mVb7t6J2Oi7p\nReDJ0jsMPRMjYsvB7kTd+Tzq7DyS9HOKMthldEdEqXe9WhxnPHANsD3F72t6RKyQtDtwXEQcK+kj\nwDlAAALOb1wepu3mACOAnwFfiBKB01YomZn1N1++mVlWHEpmlhWHkpllxaFkZllxKJlZVhxKZpYV\nh5KZZcWhZGZZcSiZWVb+HwfGnNSc+KiDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bBjGHFXXalos"
      },
      "source": [
        "## Mnist, CNN, LeNet 5, w/o Pooling, stride 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icuQlrTWassy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80da305b-3fb4-4ead-8089-4004170efd4a"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=6, kernel_size=(3, 3), strides = 2, activation='relu', input_shape=(28,28,1),name='Conv1'))\n",
        "# model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Conv2D(filters=16, kernel_size=(3, 3), strides = 2, activation='relu',name='Conv2'))\n",
        "# model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.003, momentum=0.9, nesterov=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tensboar])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Conv1 (Conv2D)               (None, 13, 13, 6)         60        \n",
            "_________________________________________________________________\n",
            "Conv2 (Conv2D)               (None, 6, 6, 16)          880       \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 120)               69240     \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 81,194\n",
            "Trainable params: 81,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.4323 - acc: 0.8709 - val_loss: 0.1625 - val_acc: 0.9514\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.1527 - acc: 0.9536 - val_loss: 0.1386 - val_acc: 0.9563\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.1130 - acc: 0.9659 - val_loss: 0.0979 - val_acc: 0.9697\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0922 - acc: 0.9722 - val_loss: 0.0940 - val_acc: 0.9704\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0762 - acc: 0.9766 - val_loss: 0.0826 - val_acc: 0.9712\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0667 - acc: 0.9790 - val_loss: 0.0782 - val_acc: 0.9743\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0587 - acc: 0.9818 - val_loss: 0.0768 - val_acc: 0.9769\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 7s 114us/step - loss: 0.0529 - acc: 0.9833 - val_loss: 0.0708 - val_acc: 0.9768\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0457 - acc: 0.9859 - val_loss: 0.0642 - val_acc: 0.9803\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0412 - acc: 0.9867 - val_loss: 0.0697 - val_acc: 0.9787\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0370 - acc: 0.9879 - val_loss: 0.0677 - val_acc: 0.9797\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 7s 111us/step - loss: 0.0328 - acc: 0.9894 - val_loss: 0.0753 - val_acc: 0.9780\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0292 - acc: 0.9909 - val_loss: 0.0620 - val_acc: 0.9807\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0262 - acc: 0.9917 - val_loss: 0.0620 - val_acc: 0.9813\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 0.0230 - acc: 0.9924 - val_loss: 0.0652 - val_acc: 0.9809\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 7s 118us/step - loss: 0.0213 - acc: 0.9931 - val_loss: 0.0662 - val_acc: 0.9817\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0196 - acc: 0.9938 - val_loss: 0.0694 - val_acc: 0.9812\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0165 - acc: 0.9950 - val_loss: 0.0701 - val_acc: 0.9810\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.0157 - acc: 0.9950 - val_loss: 0.0748 - val_acc: 0.9785\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.0156 - acc: 0.9947 - val_loss: 0.0641 - val_acc: 0.9835\n",
            "Test loss: 0.06406606653385206\n",
            "Test accuracy: 0.9835\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmgaPkK4cyyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "  if 'Conv1' in layer.name:\n",
        "    filters1, biases1 = layer.get_weights()\n",
        "  if 'Conv2' in layer.name:\n",
        "    filters2, biases2 = layer.get_weights()\n",
        "filters1 = np.squeeze(filters1)\n",
        "filters2 = np.squeeze(filters2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ax5TRyPBczro",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "7faf6085-7986-4b0b-a3c4-6e4793e382d7"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "i=0\n",
        "\n",
        "for ax in axes.flat:\n",
        "    im = ax.imshow(filters1[:,:,i], cmap='gray')\n",
        "    i+=1\n",
        "\n",
        "fig.colorbar(im, ax=axes.ravel().tolist())\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[]);\n",
        "\n",
        "fig.suptitle('Weights of first CNN layer')\n",
        "plt.savefig('mnist_comp_CNN_no_pool.pdf')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colorbar.py:214: UserWarning: Use the colorbar set_ticks() method instead.\n",
            "  warnings.warn(\"Use the colorbar set_ticks() method instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAEICAYAAACakdukAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS2JaAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ht1XSqo_Fx-g",
        "colab_type": "text"
      },
      "source": [
        "## Mnist KCNN, LeNet 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TkuGyRVER_iL",
        "outputId": "65ba9c1d-8406-45cd-b818-c89c1ba3866f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.python.keras.datasets import mnist\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.optimizers import SGD\n",
        "import keras\n",
        "import tensorflow\n",
        "from tf_keras_kervolution_2d import KernelConv1D, KernelConv2D, PolynomialKernel, LinearKernel, L1Kernel, L2Kernel, GaussianKernel\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(KernelConv2D(input_shape=input_shape, filters=6, kernel_size=3,kernel_function=PolynomialKernel(p=3, c=1), name='KConv1'))\n",
        "# model.add(KernelConv2D(input_shape=input_shape, filters=6, kernel_size=3,kernel_function=GaussianKernel(gamma=0.5), name='KConv1'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(KernelConv2D(filters=16, kernel_size=3,kernel_function=PolynomialKernel(p=3, c=1), name='KConv2'))\n",
        "# model.add(KernelConv2D(filters=16, kernel_size=3,kernel_function=GaussianKernel(gamma=0.5), name='KConv2'))\n",
        "model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.003, momentum=0.9, nesterov=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:253: calling extract_image_patches (from tensorflow.python.ops.array_ops) with ksizes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "ksizes is deprecated, use sizes instead\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "KConv1 (KernelConv2D)        (None, 26, 26, 6)         60        \n",
            "_________________________________________________________________\n",
            "average_pooling2d (AveragePo (None, 13, 13, 6)         0         \n",
            "_________________________________________________________________\n",
            "KConv2 (KernelConv2D)        (None, 11, 11, 16)        880       \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 60,074\n",
            "Trainable params: 60,074\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 14s 235us/sample - loss: 0.2731 - acc: 0.9141 - val_loss: 0.1115 - val_acc: 0.9649\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0881 - acc: 0.9725 - val_loss: 0.0651 - val_acc: 0.9812\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 14s 233us/sample - loss: 0.0637 - acc: 0.9799 - val_loss: 0.0565 - val_acc: 0.9810\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.0512 - acc: 0.9835 - val_loss: 0.0581 - val_acc: 0.9803\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.0436 - acc: 0.9859 - val_loss: 0.0499 - val_acc: 0.9824\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 14s 235us/sample - loss: 0.0362 - acc: 0.9882 - val_loss: 0.0493 - val_acc: 0.9847\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0311 - acc: 0.9901 - val_loss: 0.0524 - val_acc: 0.9855\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0287 - acc: 0.9906 - val_loss: 0.0425 - val_acc: 0.9874\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0242 - acc: 0.9922 - val_loss: 0.0425 - val_acc: 0.9881\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0208 - acc: 0.9935 - val_loss: 0.0433 - val_acc: 0.9870\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.0202 - acc: 0.9929 - val_loss: 0.0534 - val_acc: 0.9851\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0180 - acc: 0.9939 - val_loss: 0.0467 - val_acc: 0.9868\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0157 - acc: 0.9949 - val_loss: 0.0500 - val_acc: 0.9860\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 14s 229us/sample - loss: 0.0134 - acc: 0.9951 - val_loss: 0.0526 - val_acc: 0.9862\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 14s 232us/sample - loss: 0.0143 - acc: 0.9951 - val_loss: 0.0529 - val_acc: 0.9862\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.0135 - acc: 0.9956 - val_loss: 0.0488 - val_acc: 0.9879\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 14s 241us/sample - loss: 0.0111 - acc: 0.9962 - val_loss: 0.0511 - val_acc: 0.9878\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 14s 231us/sample - loss: 0.0104 - acc: 0.9966 - val_loss: 0.0476 - val_acc: 0.9885\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 14s 230us/sample - loss: 0.0105 - acc: 0.9963 - val_loss: 0.0563 - val_acc: 0.9864\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 14s 228us/sample - loss: 0.0089 - acc: 0.9969 - val_loss: 0.0631 - val_acc: 0.9861\n",
            "Test loss: 0.0630938204563876\n",
            "Test accuracy: 0.9861\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXje61Ll80eE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "  if 'KConv1' in layer.name:\n",
        "    filters1, biases1 = layer.get_weights()\n",
        "  if 'KConv2' in layer.name:\n",
        "    filters2, biases2 = layer.get_weights()\n",
        "filters1 = np.squeeze(filters1)\n",
        "filters2 = np.squeeze(filters2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Awe_yzqfCmg1",
        "colab_type": "code",
        "outputId": "06e29250-32a3-4438-940b-8774a37db8ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "i=0\n",
        "\n",
        "for ax in axes.flat:\n",
        "    im = ax.imshow(filters1[:,:,i], cmap='gray')\n",
        "    i+=1\n",
        "\n",
        "fig.colorbar(im, ax=axes.ravel().tolist())\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "fig.suptitle('Weights of first KCNN layer')\n",
        "plt.savefig('mnist_comp_KCNN_standard.pdf')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colorbar.py:214: UserWarning: Use the colorbar set_ticks() method instead.\n",
            "  warnings.warn(\"Use the colorbar set_ticks() method instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEICAYAAACJRptQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDLP51xMxxJQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFZpygkzb6fN",
        "colab_type": "text"
      },
      "source": [
        "## Mnist, KCNN, LeNet 5, w/o Pooling, stride 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlSvz66pcOmu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ccde79d7-890c-44ae-b3bf-948f7210f436"
      },
      "source": [
        "from tensorflow.python.keras.datasets import mnist\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.python.keras.layers import Conv2D, AveragePooling2D\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.optimizers import SGD\n",
        "import keras\n",
        "import tensorflow\n",
        "from tf_keras_kervolution_2d import KernelConv1D, KernelConv2D, PolynomialKernel, LinearKernel, L1Kernel, L2Kernel, GaussianKernel\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(KernelConv2D(input_shape=input_shape, filters=6,strides=2, kernel_size=3,kernel_function=PolynomialKernel(p=3, c=1), name='KConv1'))\n",
        "# model.add(KernelConv2D(input_shape=input_shape, filters=6, kernel_size=3,kernel_function=GaussianKernel(gamma=0.5), name='KConv1'))\n",
        "# model.add(AveragePooling2D())\n",
        "\n",
        "model.add(KernelConv2D(filters=16, strides=2, kernel_size=3,kernel_function=PolynomialKernel(p=3, c=1), name='KConv2'))\n",
        "# model.add(KernelConv2D(filters=16, kernel_size=3,kernel_function=GaussianKernel(gamma=0.5), name='KConv2'))\n",
        "# model.add(AveragePooling2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(units=120, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=84, activation='relu'))\n",
        "\n",
        "model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=SGD(lr=0.003, momentum=0.9, nesterov=False),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "KConv1 (KernelConv2D)        (None, 13, 13, 6)         60        \n",
            "_________________________________________________________________\n",
            "KConv2 (KernelConv2D)        (None, 6, 6, 16)          880       \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 120)               69240     \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 81,194\n",
            "Trainable params: 81,194\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "60000/60000 [==============================] - 10s 169us/sample - loss: 0.3073 - acc: 0.9088 - val_loss: 0.1281 - val_acc: 0.9593\n",
            "Epoch 2/20\n",
            "60000/60000 [==============================] - 10s 166us/sample - loss: 0.1051 - acc: 0.9674 - val_loss: 0.0833 - val_acc: 0.9740\n",
            "Epoch 3/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0737 - acc: 0.9768 - val_loss: 0.0656 - val_acc: 0.9801\n",
            "Epoch 4/20\n",
            "60000/60000 [==============================] - 10s 162us/sample - loss: 0.0569 - acc: 0.9824 - val_loss: 0.0732 - val_acc: 0.9784\n",
            "Epoch 5/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0466 - acc: 0.9858 - val_loss: 0.0631 - val_acc: 0.9808\n",
            "Epoch 6/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0379 - acc: 0.9883 - val_loss: 0.0589 - val_acc: 0.9825\n",
            "Epoch 7/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0316 - acc: 0.9901 - val_loss: 0.0603 - val_acc: 0.9821\n",
            "Epoch 8/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0268 - acc: 0.9914 - val_loss: 0.0638 - val_acc: 0.9802\n",
            "Epoch 9/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0235 - acc: 0.9916 - val_loss: 0.0600 - val_acc: 0.9826\n",
            "Epoch 10/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0200 - acc: 0.9933 - val_loss: 0.0646 - val_acc: 0.9812\n",
            "Epoch 11/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0182 - acc: 0.9940 - val_loss: 0.0553 - val_acc: 0.9846\n",
            "Epoch 12/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0148 - acc: 0.9949 - val_loss: 0.0698 - val_acc: 0.9835\n",
            "Epoch 13/20\n",
            "60000/60000 [==============================] - 9s 157us/sample - loss: 0.0133 - acc: 0.9956 - val_loss: 0.0966 - val_acc: 0.9776\n",
            "Epoch 14/20\n",
            "60000/60000 [==============================] - 10s 158us/sample - loss: 0.0126 - acc: 0.9958 - val_loss: 0.0905 - val_acc: 0.9787\n",
            "Epoch 15/20\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0091 - acc: 0.9971 - val_loss: 0.0847 - val_acc: 0.9813\n",
            "Epoch 16/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0120 - acc: 0.9961 - val_loss: 0.0777 - val_acc: 0.9815\n",
            "Epoch 17/20\n",
            "60000/60000 [==============================] - 10s 161us/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.0707 - val_acc: 0.9841\n",
            "Epoch 18/20\n",
            "60000/60000 [==============================] - 10s 160us/sample - loss: 0.0110 - acc: 0.9963 - val_loss: 0.0788 - val_acc: 0.9844\n",
            "Epoch 19/20\n",
            "60000/60000 [==============================] - 9s 158us/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 0.0793 - val_acc: 0.9837\n",
            "Epoch 20/20\n",
            "60000/60000 [==============================] - 10s 159us/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.0792 - val_acc: 0.9848\n",
            "Test loss: 0.07920337408084861\n",
            "Test accuracy: 0.9848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXIIF14ycZS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for layer in model.layers:\n",
        "  if 'KConv1' in layer.name:\n",
        "    filters1, biases1 = layer.get_weights()\n",
        "  if 'KConv2' in layer.name:\n",
        "    filters2, biases2 = layer.get_weights()\n",
        "filters1 = np.squeeze(filters1)\n",
        "filters2 = np.squeeze(filters2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RphXllqcaHS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "outputId": "3649e914-64e7-40aa-e31a-f124a8e43b5e"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=2)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "i=0\n",
        "\n",
        "for ax in axes.flat:\n",
        "    im = ax.imshow(filters1[:,:,i], cmap='gray')\n",
        "    i+=1\n",
        "\n",
        "fig.colorbar(im, ax=axes.ravel().tolist())\n",
        "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
        "fig.suptitle('Weights of first KCNN layer')\n",
        "plt.savefig('mnist_comp_KCNN_no_pool.pdf')\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/colorbar.py:214: UserWarning: Use the colorbar set_ticks() method instead.\n",
            "  warnings.warn(\"Use the colorbar set_ticks() method instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAR4AAAEICAYAAACJRptQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}